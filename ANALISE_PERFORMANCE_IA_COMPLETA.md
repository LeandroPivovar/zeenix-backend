# An√°lise Completa de Performance - Sistema de IA
## Diagn√≥stico Detalhado e Plano de Otimiza√ß√£o

**Data:** 2025-01-XX  
**Status:** üî¥ CR√çTICO - CPU em 100%  
**Prioridade:** M√ÅXIMA

---

## üìä Sum√°rio Executivo

O backend est√° consumindo **100% de CPU** devido a m√∫ltiplos gargalos cr√≠ticos no sistema de IA. Esta an√°lise identifica **8 problemas cr√≠ticos** e **12 problemas m√©dios/baixos** que precisam ser resolvidos.

**Principais Causas:**
1. üî¥ **142 chamadas `saveLog()` bloqueantes** por opera√ß√£o
2. üî¥ **Processamento sequencial** de usu√°rios (1 por vez)
3. üî¥ **Cache TTL de 1 segundo** (consultas excessivas ao banco)
4. üî¥ **Scheduler a cada 10 segundos** (ainda muito frequente)
5. üî¥ **M√∫ltiplas sincroniza√ß√µes** do banco a cada minuto
6. üî¥ **Loops aninhados** processando ticks para cada usu√°rio
7. üî¥ **WebSockets com keep-alive** a cada 30-90 segundos
8. üî¥ **Falta de batch processing** para logs e queries

---

## üîç An√°lise Detalhada do C√≥digo

### 1. üî¥ CR√çTICO: Logs Bloqueantes (142 chamadas await saveLog)

**Localiza√ß√£o:** `backend/src/ai/ai.service.ts`

**Problema:**
- **142 chamadas `await saveLog()`** encontradas no c√≥digo
- Cada chamada faz um **INSERT s√≠ncrono** no banco
- Cada INSERT leva **10-50ms**
- **Total: 1.4-7 segundos bloqueados** apenas em logs por opera√ß√£o

**C√≥digo Problem√°tico:**
```typescript
// ‚ùå PROBLEMA: Logs bloqueantes
await this.saveLog(userId, 'INFO', 'M√≥dulo', 'Mensagem');
await this.saveLog(userId, 'INFO', 'M√≥dulo', 'Outra mensagem');
// ... 140+ vezes por opera√ß√£o
```

**Impacto:**
- **Thread principal bloqueada** durante INSERTs
- **Lat√™ncia acumulada** de 1.4-7 segundos por opera√ß√£o
- **CPU ociosa** esperando I/O do banco
- **Escalabilidade zero** - n√£o suporta m√∫ltiplos usu√°rios simult√¢neos

**Solu√ß√£o:**
```typescript
// ‚úÖ SOLU√á√ÉO: Fila ass√≠ncrona de logs
private logQueue: Array<{userId: string; level: string; module: string; message: string}> = [];
private logProcessing = false;

saveLogAsync(userId: string, level: string, module: string, message: string): void {
  this.logQueue.push({ userId, level, module, message });
  if (!this.logProcessing && this.logQueue.length >= 10) {
    setImmediate(() => this.processLogQueue());
  }
}

private async processLogQueue(): Promise<void> {
  if (this.logProcessing || this.logQueue.length === 0) return;
  
  this.logProcessing = true;
  const batch = this.logQueue.splice(0, 100); // Processar at√© 100 logs
  
  try {
    if (batch.length > 0) {
      // INSERT em batch (1 query para 100 logs)
      await this.dataSource.query(
        `INSERT INTO ai_logs (user_id, level, module, message, created_at) VALUES ?`,
        [batch.map(log => [log.userId, log.level, log.module, log.message, new Date()])]
      );
    }
  } catch (error) {
    this.logger.error('[LogQueue] Erro:', error);
  } finally {
    this.logProcessing = false;
    if (this.logQueue.length > 0) {
      setImmediate(() => this.processLogQueue());
    }
  }
}

// Flush peri√≥dico (a cada 5 segundos) para garantir que logs n√£o fiquem muito tempo na fila
@Cron('*/5 * * * * *')
async flushLogQueue() {
  if (this.logQueue.length > 0) {
    await this.processLogQueue();
  }
}
```

**Redu√ß√£o Esperada:** 95-99% menos tempo bloqueado por logs

---

### 2. üî¥ CR√çTICO: Processamento Sequencial de Usu√°rios

**Localiza√ß√£o:** `backend/src/ai/ai.service.ts` (linhas 4927-4937, 4980-4989)

**Problema:**
```typescript
// ‚ùå PROBLEMA: Processamento sequencial
for (const user of fastModeUsers) {
  await this.processFastMode(user); // Processa 1 por vez
}

for (const user of usersToProcess) {
  await this.processUserAI(user); // Processa 1 por vez
}
```

**Impacto:**
- Se h√° **10 usu√°rios ativos**, processa **1 por vez**
- Cada usu√°rio leva **1-3 segundos**
- **Total: 10-30 segundos** para processar todos
- **CPU ociosa** 80% do tempo esperando I/O

**Solu√ß√£o:**
```typescript
// ‚úÖ SOLU√á√ÉO: Processamento paralelo com limite de concorr√™ncia
async processUsersInParallel<T>(
  users: T[],
  processor: (user: T) => Promise<void>,
  maxConcurrency: number = 5
): Promise<void> {
  for (let i = 0; i < users.length; i += maxConcurrency) {
    const batch = users.slice(i, i + maxConcurrency);
    await Promise.all(
      batch.map(user =>
        processor(user).catch(error => {
          this.logger.error(`[ProcessUser] Erro:`, error);
        })
      )
    );
  }
}

// Uso:
await this.processUsersInParallel(
  fastModeUsers,
  user => this.processFastMode(user),
  5 // Processar 5 usu√°rios simultaneamente
);
```

**Redu√ß√£o Esperada:** 60-80% menos tempo total de processamento

---

### 3. üî¥ CR√çTICO: Cache TTL de 1 Segundo

**Localiza√ß√£o:** `backend/src/ai/ai.service.ts` (linha 537)

**Problema:**
```typescript
// ‚ùå PROBLEMA: Cache expira muito r√°pido
private readonly CONFIG_CACHE_TTL = 1000; // 1 segundo
```

**Impacto:**
- Cache invalida **a cada segundo**
- **Consultas ao banco a cada segundo** para mesma configura√ß√£o
- Se h√° 10 usu√°rios, **10 queries por segundo** apenas para config
- **Desperd√≠cio massivo** de recursos

**Solu√ß√£o:**
```typescript
// ‚úÖ SOLU√á√ÉO: Aumentar TTL e invalidar apenas quando necess√°rio
private readonly CONFIG_CACHE_TTL = 30000; // 30 segundos

// Invalidar cache quando configura√ß√£o mudar
async updateUserConfig(userId: string, config: Partial<Config>): Promise<void> {
  await this.dataSource.query(/* UPDATE */);
  this.userConfigCache.delete(userId); // Invalidar imediatamente
}
```

**Redu√ß√£o Esperada:** 95% menos queries ao banco para configura√ß√µes

---

### 4. üî¥ CR√çTICO: Scheduler A Cada 10 Segundos

**Localiza√ß√£o:** `backend/src/ai/ai.scheduler.ts` (linha 47)

**Problema:**
```typescript
// ‚ùå PROBLEMA: Executa 6 vezes por minuto
@Cron('*/10 * * * * *', {
  name: 'process-fast-mode-ais',
})
```

**Impacto:**
- **6 execu√ß√µes por minuto** = 360 por hora
- Cada execu√ß√£o pode processar m√∫ltiplos usu√°rios
- **Consultas ao banco** a cada 10 segundos
- **Overhead constante** mesmo sem usu√°rios ativos

**Solu√ß√£o:**
```typescript
// ‚úÖ SOLU√á√ÉO: Aumentar para 30 segundos e verificar se h√° usu√°rios antes
@Cron('*/30 * * * * *', {
  name: 'process-fast-mode-ais',
})
async handleFastModeAIs() {
  if (this.isProcessingFastMode) return;
  
  // Verificar se h√° usu√°rios antes de processar
  const count = await this.aiService.getActiveUsersCount();
  if (count === 0) {
    this.logger.debug('[Scheduler] Nenhum usu√°rio ativo, pulando...');
    return;
  }
  
  this.isProcessingFastMode = true;
  try {
    await this.aiService.processFastModeUsers();
  } finally {
    this.isProcessingFastMode = false;
  }
}
```

**Redu√ß√£o Esperada:** 66% menos execu√ß√µes (de 360/h para 120/h)

---

### 5. üî¥ CR√çTICO: M√∫ltiplas Sincroniza√ß√µes do Banco

**Localiza√ß√£o:** `backend/src/ai/ai.service.ts` (linhas 4952-4957)

**Problema:**
```typescript
// ‚ùå PROBLEMA: 5 queries sequenciais a cada minuto
await this.syncVelozUsersFromDb();
await this.syncModeradoUsersFromDb();
await this.syncPrecisoUsersFromDb();
await this.syncTrinityUsersFromDb();
await this.syncAtlasUsersFromDb();
```

**Impacto:**
- **5 queries sequenciais** a cada minuto
- Cada query pode retornar dezenas de usu√°rios
- **Processamento de dados** repetido mesmo sem mudan√ßas
- **Overhead constante** mesmo sem novos usu√°rios

**Solu√ß√£o:**
```typescript
// ‚úÖ SOLU√á√ÉO: Sincronizar apenas quando necess√°rio e em batch
private lastSyncTime = 0;
private readonly SYNC_INTERVAL = 60000; // 1 minuto

async syncAllUsersFromDb(): Promise<void> {
  const now = Date.now();
  if (now - this.lastSyncTime < this.SYNC_INTERVAL) {
    return; // J√° sincronizado recentemente
  }
  
  // Buscar todos os usu√°rios ativos de uma vez
  const allUsers = await this.dataSource.query(`
    SELECT user_id, mode, stake_amount, deriv_token, currency
    FROM ai_user_config
    WHERE is_active = TRUE
  `);
  
  // Agrupar por modo e atualizar Maps
  const usersByMode = new Map<string, typeof allUsers>();
  for (const user of allUsers) {
    const mode = user.mode.toLowerCase();
    if (!usersByMode.has(mode)) {
      usersByMode.set(mode, []);
    }
    usersByMode.get(mode)!.push(user);
  }
  
  // Atualizar Maps em paralelo
  await Promise.all([
    this.updateVelozUsers(usersByMode.get('veloz') || []),
    this.updateModeradoUsers(usersByMode.get('moderado') || []),
    this.updatePrecisoUsers(usersByMode.get('preciso') || []),
    this.updateTrinityUsers(usersByMode.get('trinity') || []),
    this.updateAtlasUsers(usersByMode.get('atlas') || []),
  ]);
  
  this.lastSyncTime = now;
}
```

**Redu√ß√£o Esperada:** 80% menos queries de sincroniza√ß√£o

---

### 6. üî¥ CR√çTICO: Loops Aninhados Processando Ticks

**Localiza√ß√£o:** `backend/src/ai/strategies/orion.strategy.ts` (linhas 453-456)

**Problema:**
```typescript
// ‚ùå PROBLEMA: Processa todos os usu√°rios a cada tick
async processTick(tick: Tick, symbol?: string): Promise<void> {
  await this.processVelozStrategies(tick);
  await this.processModeradoStrategies(tick);
  await this.processPrecisoStrategies(tick);
  await this.processLentaStrategies(tick);
  
  // Dentro de cada m√©todo:
  for (const state of this.velozUsers.values()) {
    // Processa cada usu√°rio sequencialmente
  }
}
```

**Impacto:**
- **Ticks chegam a cada 1-2 segundos**
- **Cada tick processa TODOS os usu√°rios** sequencialmente
- Se h√° 20 usu√°rios, **20 processamentos por tick**
- **CPU constantemente ocupada** processando loops

**Solu√ß√£o:**
```typescript
// ‚úÖ SOLU√á√ÉO: Processar apenas usu√°rios que precisam de processamento
async processTick(tick: Tick, symbol?: string): Promise<void> {
  this.ticks.push(tick);
  if (this.ticks.length > 100) this.ticks.shift();
  
  // Processar apenas usu√°rios que coletaram ticks suficientes
  const usersToProcess = Array.from(this.velozUsers.values())
    .filter(state => state.ticksColetados >= 10 && !state.isProcessing);
  
  if (usersToProcess.length > 0) {
    // Processar em paralelo (limitado)
    await Promise.all(
      usersToProcess.slice(0, 5).map(state => 
        this.processVelozUser(state, tick).catch(error => {
          this.logger.error(`[ProcessVeloz][${state.userId}] Erro:`, error);
        })
      )
    );
  }
  
  // Incrementar ticks para todos (r√°pido, n√£o bloqueia)
  for (const state of this.velozUsers.values()) {
    state.ticksColetados++;
  }
}
```

**Redu√ß√£o Esperada:** 70-90% menos processamento desnecess√°rio

---

### 7. üî¥ CR√çTICO: WebSockets com Keep-Alive Frequente

**Localiza√ß√£o:** M√∫ltiplas estrat√©gias (trinity, atlas, apollo, etc.)

**Problema:**
```typescript
// ‚ùå PROBLEMA: Keep-alive a cada 30-90 segundos para cada conex√£o
conn.keepAliveInterval = setInterval(() => {
  if (socket.readyState === WebSocket.OPEN) {
    socket.send(JSON.stringify({ ping: 1 }));
  }
}, 30000); // 30 segundos
```

**Impacto:**
- Se h√° **10 conex√µes WebSocket**, **10 intervalos** rodando
- **Ping a cada 30-90 segundos** por conex√£o
- **Overhead de CPU** para gerenciar intervalos
- **Mem√≥ria consumida** por cada intervalo

**Solu√ß√£o:**
```typescript
// ‚úÖ SOLU√á√ÉO: Keep-alive centralizado e menos frequente
private globalKeepAliveInterval: NodeJS.Timeout | null = null;
private wsConnections = new Map<string, WebSocket>();

private startGlobalKeepAlive(): void {
  if (this.globalKeepAliveInterval) return;
  
  this.globalKeepAliveInterval = setInterval(() => {
    for (const [token, ws] of this.wsConnections.entries()) {
      if (ws && ws.readyState === WebSocket.OPEN) {
        try {
          ws.send(JSON.stringify({ ping: 1 }));
        } catch (error) {
          this.logger.warn(`[KeepAlive][${token}] Erro:`, error);
        }
      }
    }
  }, 60000); // 60 segundos (ainda menos que 2 minutos de timeout)
}
```

**Redu√ß√£o Esperada:** 50-70% menos overhead de keep-alive

---

### 8. üî¥ CR√çTICO: Falta de Batch Processing

**Localiza√ß√£o:** Todas as estrat√©gias

**Problema:**
- **Queries individuais** para cada usu√°rio
- **Logs individuais** para cada evento
- **Processamento individual** sem agrupamento

**Solu√ß√£o:**
```typescript
// ‚úÖ SOLU√á√ÉO: Batch processing para tudo
// 1. Batch queries
async getUsersConfigBatch(userIds: string[]): Promise<Map<string, Config>> {
  const result = await this.dataSource.query(
    `SELECT * FROM ai_user_config WHERE user_id IN (?)`,
    [userIds]
  );
  return new Map(result.map(r => [r.user_id, r]));
}

// 2. Batch logs (j√° mencionado acima)
// 3. Batch updates
async updateUsersNextTradeAt(updates: Array<{userId: string; nextTradeAt: Date}>): Promise<void> {
  await this.dataSource.query(
    `INSERT INTO ai_user_config (user_id, next_trade_at) VALUES ?
     ON DUPLICATE KEY UPDATE next_trade_at = VALUES(next_trade_at)`,
    [updates.map(u => [u.userId, u.nextTradeAt])]
  );
}
```

**Redu√ß√£o Esperada:** 60-80% menos queries ao banco

---

## üü° PROBLEMAS M√âDIOS

### 9. M√∫ltiplas Conex√µes WebSocket Duplicadas
- **Problema:** Cada estrat√©gia cria suas pr√≥prias conex√µes
- **Solu√ß√£o:** Usar pool centralizado `DerivWebSocketPoolService`
- **Impacto:** 40-60% menos conex√µes WebSocket

### 10. Consultas N+1
- **Problema:** Loop fazendo query individual para cada usu√°rio
- **Solu√ß√£o:** Buscar todos os dados necess√°rios em uma query
- **Impacto:** 80-90% menos queries

### 11. Processamento de Ticks Desnecess√°rio
- **Problema:** Processa todos os usu√°rios mesmo quando n√£o h√° ticks suficientes
- **Solu√ß√£o:** Verificar se usu√°rio precisa de processamento antes
- **Impacto:** 50-70% menos processamento

### 12. Falta de Debounce/Throttle
- **Problema:** M√∫ltiplas chamadas simult√¢neas para mesma opera√ß√£o
- **Solu√ß√£o:** Implementar debounce/throttle
- **Impacto:** 30-50% menos execu√ß√µes duplicadas

---

## üìã Plano de A√ß√£o Priorizado

### üî¥ FASE 1: Otimiza√ß√µes Cr√≠ticas (Implementar PRIMEIRO)

#### 1.1 Implementar Fila de Logs Ass√≠ncrona
- **Tempo:** 2-3 horas
- **Impacto:** 95-99% redu√ß√£o em tempo bloqueado
- **Prioridade:** M√ÅXIMA
- **Arquivos:**
  - `backend/src/ai/ai.service.ts`
  - `backend/src/utils/log-queue.service.ts` (criar novo)

#### 1.2 Processamento Paralelo de Usu√°rios
- **Tempo:** 2-3 horas
- **Impacto:** 60-80% redu√ß√£o em tempo total
- **Prioridade:** M√ÅXIMA
- **Arquivos:**
  - `backend/src/ai/ai.service.ts` (linhas 4909-4944, 4950-4994)

#### 1.3 Aumentar Cache TTL
- **Tempo:** 30 minutos
- **Impacto:** 95% menos queries
- **Prioridade:** M√ÅXIMA
- **Arquivos:**
  - `backend/src/ai/ai.service.ts` (linha 537)

#### 1.4 Aumentar Intervalo do Scheduler
- **Tempo:** 30 minutos
- **Impacto:** 66% menos execu√ß√µes
- **Prioridade:** M√ÅXIMA
- **Arquivos:**
  - `backend/src/ai/ai.scheduler.ts` (linha 47)

#### 1.5 Otimizar Sincroniza√ß√£o de Usu√°rios
- **Tempo:** 1-2 horas
- **Impacto:** 80% menos queries
- **Prioridade:** ALTA
- **Arquivos:**
  - `backend/src/ai/ai.service.ts` (linhas 4952-4957)

### üü° FASE 2: Otimiza√ß√µes M√©dias (Implementar DEPOIS)

#### 2.1 Otimizar Processamento de Ticks
- **Tempo:** 2-3 horas
- **Impacto:** 70-90% menos processamento
- **Arquivos:**
  - `backend/src/ai/strategies/orion.strategy.ts`
  - `backend/src/ai/strategies/nexus.strategy.ts`
  - Outras estrat√©gias

#### 2.2 Centralizar Keep-Alive de WebSockets
- **Tempo:** 2-3 horas
- **Impacto:** 50-70% menos overhead
- **Arquivos:**
  - Todas as estrat√©gias

#### 2.3 Implementar Batch Processing
- **Tempo:** 3-4 horas
- **Impacto:** 60-80% menos queries
- **Arquivos:**
  - `backend/src/ai/ai.service.ts`
  - Todas as estrat√©gias

---

## üìä M√©tricas Esperadas

### Antes das Otimiza√ß√µes
- **CPU:** 100% (constante)
- **Execu√ß√µes de schedulers:** 360/hora
- **Queries ao banco:** 100+/minuto
- **Tempo bloqueado por logs:** 1.4-7s por opera√ß√£o
- **Tempo total de processamento:** 10-30s para 10 usu√°rios
- **Conex√µes WebSocket:** M√∫ltiplas por estrat√©gia
- **Keep-alive intervals:** 10+ rodando simultaneamente

### Depois das Otimiza√ß√µes (Fase 1)
- **CPU:** 30-50% (redu√ß√£o de 50-70%)
- **Execu√ß√µes de schedulers:** 120/hora (‚Üì 67%)
- **Queries ao banco:** 5-10/minuto (‚Üì 90-95%)
- **Tempo bloqueado por logs:** 0ms (‚Üì 100%)
- **Tempo total de processamento:** 2-6s para 10 usu√°rios (‚Üì 70-80%)
- **Conex√µes WebSocket:** Centralizadas (‚Üì 50%)
- **Keep-alive intervals:** 1-2 rodando (‚Üì 80-90%)

### Depois das Otimiza√ß√µes (Fase 1 + 2)
- **CPU:** 15-30% (redu√ß√£o de 70-85%)
- **Execu√ß√µes de schedulers:** 120/hora
- **Queries ao banco:** 2-5/minuto (‚Üì 95-98%)
- **Tempo bloqueado por logs:** 0ms
- **Tempo total de processamento:** 1-3s para 10 usu√°rios (‚Üì 85-90%)
- **Conex√µes WebSocket:** Centralizadas e otimizadas
- **Keep-alive intervals:** 1 rodando

---

## ‚úÖ Checklist de Implementa√ß√£o

### Fase 1: Cr√≠ticas (Fazer PRIMEIRO)
- [ ] 1.1 Criar `LogQueueService` com fila ass√≠ncrona
- [ ] 1.2 Migrar todas chamadas `saveLog()` para `saveLogAsync()`
- [ ] 1.3 Implementar flush peri√≥dico de logs
- [ ] 1.4 Refatorar `processFastModeUsers()` para paralelo
- [ ] 1.5 Refatorar `processBackgroundAIs()` para paralelo
- [ ] 1.6 Aumentar `CONFIG_CACHE_TTL` para 30000ms
- [ ] 1.7 Aumentar intervalo do scheduler para 30s
- [ ] 1.8 Adicionar verifica√ß√£o de usu√°rios ativos no scheduler
- [ ] 1.9 Otimizar sincroniza√ß√£o de usu√°rios (batch)

### Fase 2: M√©dias (Fazer DEPOIS)
- [ ] 2.1 Otimizar processamento de ticks (filtrar usu√°rios)
- [ ] 2.2 Centralizar keep-alive de WebSockets
- [ ] 2.3 Implementar batch queries
- [ ] 2.4 Implementar batch updates
- [ ] 2.5 Adicionar debounce/throttle onde necess√°rio

---

## üöÄ Conclus√£o

O sistema de IA est√° **extremamente ineficiente** devido a:

1. **142 logs bloqueantes** por opera√ß√£o
2. **Processamento sequencial** de usu√°rios
3. **Cache TTL de 1 segundo**
4. **Scheduler muito frequente**
5. **M√∫ltiplas sincroniza√ß√µes** desnecess√°rias

**Implementando apenas a Fase 1**, esperamos:
- **50-70% de redu√ß√£o no uso de CPU**
- **90-95% menos queries ao banco**
- **100% menos tempo bloqueado por logs**
- **70-80% menos tempo total de processamento**

**Tempo total estimado:** 8-12 horas de desenvolvimento  
**Impacto esperado:** Redu√ß√£o de 50-70% no uso de CPU/Mem√≥ria

---

*Documento criado em 2025-01-XX*  
*Vers√£o: 2.0 - An√°lise Completa*


